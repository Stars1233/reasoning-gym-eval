{
  "total_datasets": 100,
  "total_examples": 5450,
  "dataset_scores": {
    "complex_arithmetic": 0.74,
    "intermediate_integration": 0.7,
    "polynomial_equations": 0.8200253067905945,
    "polynomial_multiplication": 0.26,
    "simple_equations": 0.8857142857142857,
    "simple_integration": 0.6,
    "ab": 0.0,
    "base_conversion": 0.78,
    "binary_alternation": 0.06,
    "binary_matrix": 0.06,
    "caesar_cipher": 0.0,
    "count_primes": 0.0,
    "cryptarithm": 0.28386666666666666,
    "game_of_life": 0.1092,
    "game_of_life_halting": 0.862,
    "graph_color": 0.26699999999999985,
    "group_anagrams": 0.7617999999999999,
    "isomorphic_strings": 0.7,
    "jugs": 0.0,
    "letter_counting": 0.32,
    "letter_jumble": 0.0415952380952381,
    "manipulate_matrix": 0.244,
    "number_filtering": 0.88,
    "number_sorting": 0.06,
    "palindrome_generation": 0.09419999999999998,
    "palindrome_partitioning": 0.0,
    "pool_matrix": 0.154,
    "ransom_note": 0.64,
    "rotate_matrix": 0.3,
    "rotten_oranges": 0.1,
    "sentence_reordering": 0.05597619047619047,
    "spell_backward": 0.185,
    "spiral_matrix": 0.02,
    "string_insertion": 0.22,
    "string_manipulation": 0.3701794871794871,
    "string_splitting": 0.56,
    "string_synthesis": 0.62,
    "word_ladder": 0.0,
    "word_sequence_reversal": 0.0,
    "word_sorting": 0.044000000000000004,
    "arc_1d": 0.24,
    "arc_agi": 0.012,
    "rearc": 0.10899999999999999,
    "basic_arithmetic": 0.54,
    "bitwise_arithmetic": 0.0,
    "calendar_arithmetic": 0.6560000000000001,
    "chain_sum": 0.96,
    "count_bits": 0.0,
    "decimal_arithmetic": 0.18,
    "decimal_chain_sum": 0.48,
    "dice": 0.0,
    "fraction_simplification": 0.031400000000000004,
    "gcd": 0.48,
    "gsm_symbolic": 0.8403999999999999,
    "lcm": 0.66,
    "leg_counting": 0.52,
    "number_format": 0.06,
    "power_function": 0.0652,
    "prime_factorization": 0.48019999999999996,
    "products": 0.24,
    "time_intervals": 0.6190699537037037,
    "bf": 0.0,
    "codeio": 3503975.1834794944,
    "color_cube_rotation": 0.28699999999999987,
    "figlet_font": 0.02,
    "modulo_grid": 0.06,
    "needle_haystack": 0.06,
    "number_sequence": 0.54,
    "rectangle_count": 0.2,
    "rubiks_cube": 0.02240000000000001,
    "countdown": 0.010800000000000008,
    "emoji_mystery": 0.010000000000000004,
    "futoshiki": 0.07501316326530612,
    "knight_swap": 0.26,
    "mahjong_puzzle": 0.24,
    "maze": 0.0,
    "mini_sudoku": 0.007875,
    "n_queens": 0.02,
    "puzzle24": 0.04959999999999983,
    "rush_hour": 0.0,
    "sokoban": 0.02,
    "sudoku": 0.04777777777777779,
    "tower_of_hanoi": 0.0,
    "tsumego": 0.10099999999999992,
    "advanced_geometry": 0.3174,
    "simple_geometry": 0.40199999999999997,
    "course_schedule": 0.48,
    "family_relationships": 0.22,
    "largest_island": 0.28,
    "quantum_lock": 0.35,
    "shortest_path": 0.18,
    "acre": 0.0,
    "list_functions": 0.44,
    "aiw": 0.26,
    "circuit_logic": 0.3,
    "knights_knaves": 0.5779999999999998,
    "propositional_logic": 0.29600000000000004,
    "self_reference": 0.0,
    "syllogism": 0.72,
    "zebra_puzzles": 0.34
  },
  "timestamp": "2025-03-10T00:49:50.662433",
  "git_hash": "4109b5b72cfe9975cbebc3a8ee08f465fe40f14b",
  "model": "meta-llama/llama-3.3-70b-instruct",
  "provider": "Hyperbolic",
  "system_prompt": "Given a problem, your task is to answer the question by thinking step-by-step in a clear and specific manner.\nOnce you have thought about the reasoning process, provide the answer in the following format:\n<answer>answer here</answer>\nDo not explain your reasoning inside the answer tags, provide only the final answer. When an example is provided, you should strictly follow the format of the output/answer in that example.\n",
  "max_tokens": 32768,
  "temperature": 0.6,
  "top_p": 0.95,
  "duration_seconds": 10929.790272
}